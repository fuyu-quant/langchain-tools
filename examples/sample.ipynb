{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCT-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain-tools/blob/main/examples/sample.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\n",
      "----------------------------- -----------\n",
      "aiofiles                      22.1.0\n",
      "aiohttp                       3.8.4\n",
      "aiosignal                     1.3.1\n",
      "aiosqlite                     0.18.0\n",
      "alembic                       1.10.2\n",
      "altair                        4.2.2\n",
      "anyio                         3.6.2\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "asttokens                     2.2.1\n",
      "async-generator               1.10\n",
      "async-timeout                 4.0.2\n",
      "attrs                         22.2.0\n",
      "Babel                         2.12.1\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.11.2\n",
      "bleach                        6.0.0\n",
      "blinker                       1.5\n",
      "bokeh                         2.4.3\n",
      "Bottleneck                    1.3.7\n",
      "brotlipy                      0.7.0\n",
      "cached-property               1.5.2\n",
      "certifi                       2022.12.7\n",
      "certipy                       0.1.3\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            2.1.1\n",
      "click                         8.1.3\n",
      "cloudpickle                   2.2.1\n",
      "colorama                      0.4.6\n",
      "comm                          0.1.2\n",
      "conda                         23.1.0\n",
      "conda-package-handling        2.0.2\n",
      "conda_package_streaming       0.7.0\n",
      "contourpy                     1.0.7\n",
      "cryptography                  39.0.2\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.33\n",
      "cytoolz                       0.12.0\n",
      "dask                          2023.3.1\n",
      "dataclasses-json              0.5.7\n",
      "debugpy                       1.6.6\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "dill                          0.3.6\n",
      "distributed                   2023.3.1\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     1.2.0\n",
      "fastjsonschema                2.16.3\n",
      "flit_core                     3.8.0\n",
      "fonttools                     4.39.0\n",
      "frozenlist                    1.3.3\n",
      "fsspec                        2023.3.0\n",
      "gmpy2                         2.1.2\n",
      "greenlet                      2.0.2\n",
      "h5py                          3.8.0\n",
      "HeapDict                      1.0.1\n",
      "idna                          3.4\n",
      "imagecodecs                   2023.1.23\n",
      "imageio                       2.26.0\n",
      "importlib-metadata            6.0.0\n",
      "importlib-resources           5.12.0\n",
      "ipykernel                     6.21.3\n",
      "ipympl                        0.9.3\n",
      "ipython                       8.11.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.0.4\n",
      "jedi                          0.18.2\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.2.0\n",
      "json5                         0.9.5\n",
      "jsonschema                    4.17.3\n",
      "jupyter_client                8.0.3\n",
      "jupyter_core                  5.2.0\n",
      "jupyter-events                0.6.3\n",
      "jupyter_server                2.4.0\n",
      "jupyter_server_fileid         0.8.0\n",
      "jupyter_server_terminals      0.4.4\n",
      "jupyter_server_ydoc           0.6.1\n",
      "jupyter-telemetry             0.1.0\n",
      "jupyter-ydoc                  0.2.2\n",
      "jupyterhub                    3.1.1\n",
      "jupyterlab                    3.6.1\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab_server             2.20.0\n",
      "jupyterlab-widgets            3.0.5\n",
      "kiwisolver                    1.4.4\n",
      "langchain                     0.0.148\n",
      "langchaintools                0.1\n",
      "libmambapy                    1.3.1\n",
      "lightgbm                      3.3.5\n",
      "llvmlite                      0.39.1\n",
      "locket                        1.0.0\n",
      "lz4                           4.3.2\n",
      "Mako                          1.2.4\n",
      "mamba                         1.3.1\n",
      "MarkupSafe                    2.1.2\n",
      "marshmallow                   3.19.0\n",
      "marshmallow-enum              1.5.1\n",
      "matplotlib                    3.7.1\n",
      "matplotlib-inline             0.1.6\n",
      "mistune                       2.0.5\n",
      "mpmath                        1.3.0\n",
      "msgpack                       1.0.5\n",
      "multidict                     6.0.4\n",
      "munkres                       1.1.4\n",
      "mypy-extensions               1.0.0\n",
      "nbclassic                     0.5.3\n",
      "nbclient                      0.7.2\n",
      "nbconvert                     7.2.9\n",
      "nbformat                      5.7.3\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.0\n",
      "notebook                      6.5.3\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.56.4\n",
      "numexpr                       2.8.4\n",
      "numpy                         1.23.5\n",
      "oauthlib                      3.2.2\n",
      "openai                        0.27.4\n",
      "openapi-schema-pydantic       1.2.4\n",
      "openpyxl                      3.1.1\n",
      "packaging                     23.0\n",
      "pamela                        1.0.0\n",
      "pandas                        1.5.3\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "partd                         1.3.0\n",
      "patsy                         0.5.3\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.0.1\n",
      "pkgutil_resolve_name          1.3.10\n",
      "platformdirs                  3.1.1\n",
      "pluggy                        1.0.0\n",
      "pooch                         1.7.0\n",
      "prometheus-client             0.16.0\n",
      "prompt-toolkit                3.0.38\n",
      "protobuf                      4.21.12\n",
      "psutil                        5.9.4\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pyarrow                       11.0.0\n",
      "pycosat                       0.6.4\n",
      "pycparser                     2.21\n",
      "pycurl                        7.45.1\n",
      "pydantic                      1.10.7\n",
      "Pygments                      2.14.0\n",
      "PyJWT                         2.6.0\n",
      "pyOpenSSL                     23.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.19.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.7\n",
      "pytz                          2022.7.1\n",
      "pytz-deprecation-shim         0.1.0.post0\n",
      "PyWavelets                    1.4.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         25.0.0\n",
      "requests                      2.28.2\n",
      "rfc3339-validator             0.1.4\n",
      "rfc3986-validator             0.1.1\n",
      "rpy2                          3.5.10\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.7\n",
      "scikit-image                  0.19.3\n",
      "scikit-learn                  1.2.2\n",
      "scipy                         1.10.1\n",
      "seaborn                       0.12.2\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    67.6.0\n",
      "simplegeneric                 0.8.1\n",
      "six                           1.16.0\n",
      "sniffio                       1.3.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.2.post1\n",
      "SQLAlchemy                    1.4.47\n",
      "stack-data                    0.6.2\n",
      "statsmodels                   0.13.5\n",
      "sympy                         1.11.1\n",
      "tables                        3.7.0\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "terminado                     0.17.1\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2023.2.28\n",
      "tinycss2                      1.2.1\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "tornado                       6.2\n",
      "tqdm                          4.65.0\n",
      "traitlets                     5.9.0\n",
      "typing_extensions             4.5.0\n",
      "typing-inspect                0.8.0\n",
      "tzdata                        2022.7\n",
      "tzlocal                       4.2\n",
      "unicodedata2                  15.0.0\n",
      "urllib3                       1.26.15\n",
      "wcwidth                       0.2.6\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.5.1\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            4.0.5\n",
      "xlrd                          2.0.1\n",
      "y-py                          0.5.9\n",
      "yarl                          1.9.1\n",
      "ypy-websocket                 0.8.2\n",
      "zict                          2.2.0\n",
      "zipp                          3.15.0\n",
      "zstandard                     0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicationTool(BaseTool):\n",
    "    name = \"MultiplicationTool\"\n",
    "    description = \"\"\"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "      \"\"\"Use the tool.\"\"\"\n",
    "      a, b = query.split(\",\")\n",
    "      c = int(a) * int(b)\n",
    "      result = c\n",
    "\n",
    "      return result \n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MultiplicationTool()]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to multiply two numbers\n",
      "Action: MultiplicationTool\n",
      "Action Input: 38,47\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1786\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 38 times 47 is 1786.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'38 times 47 is 1786.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('38 times 47?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm('38 times 47?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参照するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = 'trainig XGBoost'\n",
    "input = 'training LightGBM'\n",
    "exec_list = [\n",
    "    'training LightGBM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deciding_agent(input_, exec_list_):\n",
    "    print(\"deciding agent\")\n",
    "    \n",
    "    decide_llm = OpenAI(temperature=0,model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    i = ''\n",
    "    for i in exec_list:\n",
    "        i = i + ','\n",
    "    i = '[' + i + ']'\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are an agent that determines if the input task is executable. \n",
    "    All you can do is to be included in {exec_list}. \n",
    "    Answer \"Yes.\" if you can perform the task, or \"No.\" if you cannot.\n",
    "    ------\n",
    "    The entered task is:{input}\n",
    "    ------\n",
    "    \"\"\".format(exec_list = i,input = input_)\n",
    "\n",
    "    return decide_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:672: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deciding_agent(input, exec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 道具をつくるLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolmaking_agent(input_):\n",
    "    print(\"toolmaking agent\")\n",
    "\n",
    "    toolmaking_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Create a python function that can execute {input} with a single string as input.\n",
    "    The code below is the code created with the input \"multiply two numbers\".\n",
    "    The output is only the code of the created python.\n",
    "    ```\n",
    "    from dataclasses import dataclass\n",
    "\n",
    "    @dataclass\n",
    "    class NewTool(BaseTool):\n",
    "        name = \"MultiplicationTool\"\n",
    "        description = \"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\n",
    "\n",
    "        def _run(self, query: str) -> str:\n",
    "            \"Use the tool.\"\n",
    "            a, b = query.split(\",\")\n",
    "            c = int(a) * int(b)\n",
    "            result = c\n",
    "\n",
    "        return result \n",
    "\n",
    "        async def _arun(self, query: str) -> str:\n",
    "            \"Use the tool asynchronously.\"\n",
    "            raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "    ```\n",
    "    \"\"\".format(input = input_)\n",
    "\n",
    "    code = toolmaking_llm(prompt)\n",
    "\n",
    "\n",
    "    file = open('/content/new_tool.py', mode='w')\n",
    "    file.write(code)\n",
    "    file.close()\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolmaking agent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finish'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = 'Output multiples of 3 up to 20'\n",
    "toolmaking_agent(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executing_agent(input_, tools_):\n",
    "    print(\"executing agent\")\n",
    "\n",
    "    excute_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    agent = initialize_agent(tools_, excute_llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "    agent.run(input_)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_, exec_list_, tools_):\n",
    "    \n",
    "    output = deciding_agent(input_, exec_list_)\n",
    "\n",
    "    if output == \"Yes\":\n",
    "        print('Execute it as it is executable without creating a tool.')\n",
    "        executing_agent(input_, tools_)\n",
    "\n",
    "    elif output == \"No\":\n",
    "        print('It is necessary to create a tool, so run it after creating the tool.')\n",
    "        new_tool = toolmaking_agent(input_)\n",
    "\n",
    "        exec(new_tool)\n",
    "\n",
    "        tools_.append(NewTool())\n",
    "\n",
    "        executing_agent(input_, tools_)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "\n",
    "\n",
    "class LCTAGI():\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name = 'gpt-4'\n",
    "        ):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    \n",
    "    def _generalize(self, input_prompt_):\n",
    "\n",
    "        generalize_llm = OpenAI(temperature=0,model_name = self.model_name)\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Please generalize the following sentences by replacing any numerical or other parts of the sentences with letters.\n",
    "        Output is only the text after rewriting.\n",
    "\n",
    "        ------------\n",
    "        {input}\n",
    "        ------------\n",
    "        \"\"\".format(input = input_prompt_)\n",
    "\n",
    "        responese = generalize_llm(prompt)\n",
    "\n",
    "        print(f'Generalized Task：{responese}')\n",
    "\n",
    "        return responese\n",
    "        \n",
    "\n",
    "    def _decide(self, input_prompt_, tools_):\n",
    "        print(\"Determine if you should make a tool.\")\n",
    "        \n",
    "        decide_llm = OpenAI(temperature=0,model_name = self.model_name)\n",
    "\n",
    "        description_list = ''\n",
    "        for tool_ in tools_:\n",
    "            description = tool_.description\n",
    "            description_list += description + ','\n",
    "        description_list = '[' + description_list + ']'\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        You are an agent that determines if the input task is executable. \n",
    "        All you can do is to be included in {exec_list}. \n",
    "        Answer \"Yes.\" if you can perform the task, or \"No.\" if you cannot.\n",
    "        \n",
    "        -----------\n",
    "        The entered task is:{input}\n",
    "        -----------\n",
    "        \"\"\".format(exec_list = description_list, input = input_prompt_)\n",
    "\n",
    "        responese = decide_llm(prompt)\n",
    "\n",
    "        if responese == \"Yes.\":\n",
    "            print('Execute it as it is executable without creating a tool.')\n",
    "\n",
    "        elif responese == \"No.\":\n",
    "            print('It is necessary to create a tool, so run it after creating the tool.')\n",
    "\n",
    "\n",
    "        return responese\n",
    "\n",
    "\n",
    "    def _tool_make(self, input_prompt_, folder_path_):\n",
    "        print(\"Create a TOOL.\")\n",
    "\n",
    "        tool_llm = OpenAI(temperature=0, model_name = self.model_name)\n",
    "\n",
    "\n",
    "        create_prompt = \"\"\"\n",
    "        Create a python class that can execute {input} with a single string as input.\n",
    "        Output should be code only.\n",
    "        The following code was created with the input \"multiply two numbers\". Please create it like this code.\n",
    "        Do not enclose the output in ``python ``` or the like.\n",
    "        \n",
    "        ------------------\n",
    "        from dataclasses import dataclass\n",
    "\n",
    "        @dataclass\n",
    "        class MultiplicationTool(BaseTool):\n",
    "            name = \"MultiplicationTool\"\n",
    "            description = \"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\n",
    "\n",
    "            def _run(self, query: str) -> str:\n",
    "                \"Use the tool.\"\n",
    "                a, b = query.split(\",\")\n",
    "                c = int(a) * int(b)\n",
    "                result = c\n",
    "\n",
    "            return result \n",
    "\n",
    "            async def _arun(self, query: str) -> str:\n",
    "                \"Use the tool asynchronously.\"\n",
    "                raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "        ------------------\n",
    "        \"\"\".format(input = input_prompt_)\n",
    "\n",
    "        code = tool_llm(create_prompt)\n",
    "        #print('Created Code：\\n' + code)\n",
    "\n",
    "\n",
    "\n",
    "        name_prompt = \"\"\"\n",
    "        Get the name of the class from the following code.\n",
    "        Output is name only.\n",
    "\n",
    "        ------------------\n",
    "        {code}\n",
    "        ------------------\n",
    "        \"\"\".format(code = code)\n",
    "\n",
    "        name = tool_llm(name_prompt)\n",
    "        print('Created tool name：' + name)\n",
    "\n",
    "        # Save to File\n",
    "        if folder_path_ != None:\n",
    "            with open(folder_path_ + f'{name}.py', mode='w') as file:\n",
    "                file.write(code)\n",
    "        \n",
    "\n",
    "        return name, code\n",
    "\n",
    "\n",
    "    def _execute(self,input_prompt_, tools_):\n",
    "        print(\"tool to execute it.\")\n",
    "\n",
    "        excute_llm = OpenAI(temperature=0, model_name = self.model_name)\n",
    "\n",
    "        agent = initialize_agent(tools_, excute_llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "        agent.run(input_prompt_)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def run(self, input_prompt_, tools_, folder_path_ = None):\n",
    "\n",
    "        generalized_task = self._generalize(input_prompt_)\n",
    "    \n",
    "        output = self._decide(generalized_task, tools_)\n",
    "\n",
    "        if output == \"Yes.\":\n",
    "            self._execute(input_prompt_, tools_)\n",
    "\n",
    "        elif output == \"No.\":\n",
    "            new_tool_name, new_tool_code = self._tool_make(generalized_task, folder_path_)\n",
    "\n",
    "            exec(new_tool_code)\n",
    "\n",
    "            exec(f'new_tool = {new_tool_name}()')\n",
    "\n",
    "            tools_.append(new_tool)\n",
    "\n",
    "            print(tools_)\n",
    "            \n",
    "            self._execute(input_prompt_, tools_)\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Task：Sum of prime numbers from A to B\n",
      "Determine if you should make a tool.\n",
      "It is necessary to create a tool, so run it after creating the tool.\n",
      "Create a TOOL.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m tools \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m lctagi \u001b[38;5;241m=\u001b[39m LCTAGI()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlctagi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#lctagi.run(input, tools)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[107], line 148\u001b[0m, in \u001b[0;36mLCTAGI.run\u001b[0;34m(self, input_prompt_, tools_, folder_path_)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(input_prompt_, tools_)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m output \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     new_tool_name, new_tool_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tool_make\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneralized_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m     exec(new_tool_code)\n\u001b[1;32m    152\u001b[0m     exec(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_tool = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_tool_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[107], line 114\u001b[0m, in \u001b[0;36mLCTAGI._tool_make\u001b[0;34m(self, input_prompt_, folder_path_)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#print('Created Code：\\n' + code)\u001b[39;00m\n\u001b[1;32m    105\u001b[0m name_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124mGet the name of the class from the following code.\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124mOutput is name only.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;124m------------------\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(code \u001b[38;5;241m=\u001b[39m code)\n\u001b[0;32m--> 114\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[43mtool_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated tool name：\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Save to File\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:246\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, prompt: \u001b[39mstr\u001b[39m, stop: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m    245\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check Cache and run the LLM on the given prompt and input.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate([prompt], stop\u001b[39m=\u001b[39;49mstop)\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:140\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    141\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_end(output, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/base.py:137\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    134\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m}, prompts, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(prompts, stop\u001b[39m=\u001b[39;49mstop)\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_llm_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:720\u001b[0m, in \u001b[0;36mOpenAIChat._generate\u001b[0;34m(self, prompts, stop)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(\n\u001b[1;32m    717\u001b[0m         generations\u001b[39m=\u001b[39m[[Generation(text\u001b[39m=\u001b[39mresponse)]],\n\u001b[1;32m    718\u001b[0m     )\n\u001b[1;32m    719\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m     full_response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    721\u001b[0m     llm_output \u001b[39m=\u001b[39m {\n\u001b[1;32m    722\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtoken_usage\u001b[39m\u001b[39m\"\u001b[39m: full_response[\u001b[39m\"\u001b[39m\u001b[39musage\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m    723\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_name,\n\u001b[1;32m    724\u001b[0m     }\n\u001b[1;32m    725\u001b[0m     \u001b[39mreturn\u001b[39;00m LLMResult(\n\u001b[1;32m    726\u001b[0m         generations\u001b[39m=\u001b[39m[\n\u001b[1;32m    727\u001b[0m             [Generation(text\u001b[39m=\u001b[39mfull_response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])]\n\u001b[1;32m    728\u001b[0m         ],\n\u001b[1;32m    729\u001b[0m         llm_output\u001b[39m=\u001b[39mllm_output,\n\u001b[1;32m    730\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:102\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:100\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[1;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/openai/api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    514\u001b[0m     _thread_context\u001b[39m.\u001b[39msession \u001b[39m=\u001b[39m _make_session()\n\u001b[1;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    517\u001b[0m         method,\n\u001b[1;32m    518\u001b[0m         abs_url,\n\u001b[1;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    524\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    582\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    583\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    584\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    585\u001b[0m }\n\u001b[1;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input = 'Sum of prime numbers from 1 to 50'\n",
    "\n",
    "folder_path = '/home/langchain-tools/data/'\n",
    "tools = []\n",
    "\n",
    "lctagi = LCTAGI()\n",
    "\n",
    "lctagi.run(input, tools, folder_path)\n",
    "\n",
    "#lctagi.run(input, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "class MultiplicationTool(BaseTool):\n",
    "    name = \"MultiplicationTool\"\n",
    "    description = \"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "      \"Use the tool.\"\n",
    "      a, b = query.split(\",\")\n",
    "      c = int(a) * int(b)\n",
    "      result = c\n",
    "\n",
    "      return result \n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"Use the tool asynchronously.\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiplicationTool()"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = MultiplicationTool()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_code = \"\"\"\n",
    "class NewTool(BaseTool):\n",
    "    name = \"SumOfPrimesTool\"\n",
    "    description = \"used for calculating the sum of prime numbers from 1 to 50. The input is a single string.\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"Use the tool.\"\n",
    "        def is_prime(num):\n",
    "            if num < 2:\n",
    "                return False\n",
    "            for i in range(2, num):\n",
    "                if num % i == 0:\n",
    "                    return False\n",
    "            return True\n",
    "\n",
    "        prime_sum = sum(filter(is_prime, range(1, 51)))\n",
    "        result = prime_sum\n",
    "\n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"Use the tool asynchronously.\"\n",
    "        raise NotImplementedError(\"SumOfPrimesTool does not support async\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NewTool(name='SumOfPrimesTool', description='used for calculating the sum of prime numbers from 1 to 50. The input is a single string.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0xffff71f1b010>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(tool_code)\n",
    "\n",
    "new_tool = NewTool()\n",
    "new_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MultiplicationTool(name='MultiplicationTool', description=\"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\", args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0xffff71f1b010>),\n",
       " NewTool(name='SumOfPrimesTool', description='used for calculating the sum of prime numbers from 1 to 50. The input is a single string.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0xffff71f1b010>)]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exec(code)\n",
    "\n",
    "a = MultiplicationTool()\n",
    "\n",
    "tools = []\n",
    "tools.append(a)\n",
    "\n",
    "exec(tool_code)\n",
    "\n",
    "b = NewTool()\n",
    "\n",
    "tools.append(b)\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultiplicationTool' object has no attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43minitialize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero-shot-react-description\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m agent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m38 times 47?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/initialize.py:52\u001b[0m, in \u001b[0;36minitialize_agent\u001b[0;34m(tools, llm, agent, callback_manager, agent_path, agent_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m     agent_cls \u001b[39m=\u001b[39m AGENT_TO_CLASS[agent]\n\u001b[1;32m     51\u001b[0m     agent_kwargs \u001b[39m=\u001b[39m agent_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[0;32m---> 52\u001b[0m     agent_obj \u001b[39m=\u001b[39m agent_cls\u001b[39m.\u001b[39;49mfrom_llm_and_tools(\n\u001b[1;32m     53\u001b[0m         llm, tools, callback_manager\u001b[39m=\u001b[39;49mcallback_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49magent_kwargs\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m \u001b[39melif\u001b[39;00m agent_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     agent_obj \u001b[39m=\u001b[39m load_agent(\n\u001b[1;32m     57\u001b[0m         agent_path, llm\u001b[39m=\u001b[39mllm, tools\u001b[39m=\u001b[39mtools, callback_manager\u001b[39m=\u001b[39mcallback_manager\n\u001b[1;32m     58\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:101\u001b[0m, in \u001b[0;36mZeroShotAgent.from_llm_and_tools\u001b[0;34m(cls, llm, tools, callback_manager, output_parser, prefix, suffix, format_instructions, input_variables, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_llm_and_tools\u001b[39m(\n\u001b[1;32m     89\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     99\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Agent:\n\u001b[1;32m    100\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Construct an agent from an LLM and tools.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_tools(tools)\n\u001b[1;32m    102\u001b[0m     prompt \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcreate_prompt(\n\u001b[1;32m    103\u001b[0m         tools,\n\u001b[1;32m    104\u001b[0m         prefix\u001b[39m=\u001b[39mprefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m         input_variables\u001b[39m=\u001b[39minput_variables,\n\u001b[1;32m    108\u001b[0m     )\n\u001b[1;32m    109\u001b[0m     llm_chain \u001b[39m=\u001b[39m LLMChain(\n\u001b[1;32m    110\u001b[0m         llm\u001b[39m=\u001b[39mllm,\n\u001b[1;32m    111\u001b[0m         prompt\u001b[39m=\u001b[39mprompt,\n\u001b[1;32m    112\u001b[0m         callback_manager\u001b[39m=\u001b[39mcallback_manager,\n\u001b[1;32m    113\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/mrkl/base.py:126\u001b[0m, in \u001b[0;36mZeroShotAgent._validate_tools\u001b[0;34m(cls, tools)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_tools\u001b[39m(\u001b[39mcls\u001b[39m, tools: Sequence[BaseTool]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mfor\u001b[39;00m tool \u001b[39min\u001b[39;00m tools:\n\u001b[0;32m--> 126\u001b[0m         \u001b[39mif\u001b[39;00m tool\u001b[39m.\u001b[39;49mdescription \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    128\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot a tool \u001b[39m\u001b[39m{\u001b[39;00mtool\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m without a description. For this agent, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39ma description must always be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m             )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MultiplicationTool' object has no attribute 'description'"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "agent.run('38 times 47?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(code)\n",
    "            \n",
    "new_tool = NewTool()\n",
    "            \n",
    "tools_.append(new_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NewTool(name='SumOfPrimesTool', description='used for calculating the sum of prime numbers from 1 to 50. The input is a single string.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0xffff71f1b010>)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = []\n",
    "\n",
    "new_tool_name = 'NewTool'\n",
    "\n",
    "exec(f'b_tool = {new_tool_name}()')\n",
    "\n",
    "tools.append(b_tool)\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(tool_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(f'tools_.append({tool_name}())')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NewTool(name='SumOfPrimesTool', description='used for calculating the sum of prime numbers from 1 to 50. The input is a single string.', args_schema=None, return_direct=False, verbose=False, callback_manager=<langchain.callbacks.shared.SharedCallbackManager object at 0xffff71f1b010>)]\n"
     ]
    }
   ],
   "source": [
    "tools = []\n",
    "\n",
    "exec(f'tools.append(NewTool())')\n",
    "\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [NewTool()]\n",
    "\n",
    "#tools = [MultiplicationTool()]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find the sum of prime numbers from 1 to 50\n",
      "Action: SumOfPrimesTool\n",
      "Action Input: \"1 to 50\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m328\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the sum of prime numbers from 1 to 50\n",
      "Final Answer: 328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'328'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = 'Sum of prime numbers from 1 to 50'\n",
    "\n",
    "agent.run(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
