{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCT-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain-tools/blob/main/examples/sample.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplicationTool(BaseTool):\n",
    "    name = \"MultiplicationTool\"\n",
    "    description = \"\"\"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "      \"\"\"Use the tool.\"\"\"\n",
    "      a, b = query.split(\",\")\n",
    "      c = int(a) * int(b)\n",
    "      result = c\n",
    "\n",
    "      return result \n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MultiplicationTool()]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to multiply two numbers\n",
      "Action: MultiplicationTool\n",
      "Action Input: 38,47\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m1786\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 38 times 47 is 1786.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'38 times 47 is 1786.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('38 times 47?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm('38 times 47?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参照するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = 'trainig XGBoost'\n",
    "input = 'training LightGBM'\n",
    "exec_list = [\n",
    "    'training LightGBM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deciding_agent(input_, exec_list_):\n",
    "    print(\"deciding agent\")\n",
    "    \n",
    "    decide_llm = OpenAI(temperature=0,model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    i = ''\n",
    "    for i in exec_list:\n",
    "        i = i + ','\n",
    "    i = '[' + i + ']'\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are an agent that determines if the input task is executable. \n",
    "    All you can do is to be included in {exec_list}. \n",
    "    Answer \"Yes.\" if you can perform the task, or \"No.\" if you cannot.\n",
    "    ------\n",
    "    The entered task is:{input}\n",
    "    ------\n",
    "    \"\"\".format(exec_list = i,input = input_)\n",
    "\n",
    "    return decide_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:672: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deciding_agent(input, exec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 道具をつくるLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolmaking_agent(input_):\n",
    "    print(\"toolmaking agent\")\n",
    "\n",
    "    toolmaking_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Create a python function that can execute {input} with a single string as input.\n",
    "    The code below is the code created with the input \"multiply two numbers\".\n",
    "    The output is only the code of the created python.\n",
    "    ```\n",
    "    from dataclasses import dataclass\n",
    "\n",
    "    @dataclass\n",
    "    class NewTool(BaseTool):\n",
    "        name = \"MultiplicationTool\"\n",
    "        description = \"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\n",
    "\n",
    "        def _run(self, query: str) -> str:\n",
    "            \"Use the tool.\"\n",
    "            a, b = query.split(\",\")\n",
    "            c = int(a) * int(b)\n",
    "            result = c\n",
    "\n",
    "        return result \n",
    "\n",
    "        async def _arun(self, query: str) -> str:\n",
    "            \"Use the tool asynchronously.\"\n",
    "            raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "    ```\n",
    "    \"\"\".format(input = input_)\n",
    "\n",
    "    code = toolmaking_llm(prompt)\n",
    "\n",
    "\n",
    "    file = open('/content/new_tool.py', mode='w')\n",
    "    file.write(code)\n",
    "    file.close()\n",
    "\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolmaking agent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finish'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = 'Output multiples of 3 up to 20'\n",
    "toolmaking_agent(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executing_agent(input_, tools_):\n",
    "    print(\"executing agent\")\n",
    "\n",
    "    excute_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    agent = initialize_agent(tools_, excute_llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "    agent.run(input_)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_, exec_list_, tools_):\n",
    "    \n",
    "    output = deciding_agent(input_, exec_list_)\n",
    "\n",
    "    if output == \"Yes\":\n",
    "        print('Execute it as it is executable without creating a tool.')\n",
    "        executing_agent(input_, tools_)\n",
    "\n",
    "    elif output == \"No\":\n",
    "        print('It is necessary to create a tool, so run it after creating the tool.')\n",
    "        new_tool = toolmaking_agent(input_)\n",
    "\n",
    "        exec(new_tool)\n",
    "\n",
    "        tools_.append(NewTool())\n",
    "\n",
    "        executing_agent(input_, tools_)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
