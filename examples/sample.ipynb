{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCT-AGI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain-tools/blob/main/examples/sample.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参照するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input = 'trainig XGBoost'\n",
    "input = 'training LightGBM'\n",
    "exec_list = [\n",
    "    'training LightGBM'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deciding_agent(input_, exec_list_):\n",
    "    print(\"deciding agent\")\n",
    "    \n",
    "    decide_llm = OpenAI(temperature=0,model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    i = ''\n",
    "    for i in exec_list:\n",
    "        i = i + ','\n",
    "    i = '[' + i + ']'\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    You are an agent that determines if the input task is executable. \n",
    "    All you can do is to be included in {exec_list}. \n",
    "    Answer \"Yes\" if you can perform the task, or \"No\" if you cannot.\n",
    "    ------\n",
    "    The entered task is:{input}\n",
    "    ------\n",
    "    \"\"\".format(exec_list = i,input = input_)\n",
    "\n",
    "    return decide_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:165: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain/llms/openai.py:672: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deciding_agent(input, exec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 道具をつくるLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toolmaking_agent(input_):\n",
    "    print(\"toolmaking agent\")\n",
    "\n",
    "    toolmaking_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Create a python function that can execute {input} with a single string as input.\n",
    "    The code below is the code created with the input \"multiply two numbers\".\n",
    "    The output is only the code of the created python.\n",
    "    -----------------------------------\n",
    "    @tool('new_tool')\n",
    "    def new_tool(query: str) -> str:\n",
    "        'Used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.'\n",
    "        a, b = query.split(\",\")\n",
    "        c = int(a) * int(b)\n",
    "        return c\n",
    "    \"\"\".format(input = input_)\n",
    "\n",
    "    code = toolmaking_llm(prompt)\n",
    "\n",
    "    #name = query.replace(' ','_').lower()\n",
    "\n",
    "    #bos = \"\\n@tool('{name}_tool)\\n\"\\\n",
    "    #        \"def {name}_tool(query: str) -> str:\\n\"\\\n",
    "    #        \"    'useful for {query}'\"\n",
    "    \n",
    "    #code = textwrap.indent(textwrap.dedent(code)[:], '    ')\n",
    "\n",
    "    #eos = \"\\n    result = 'finish {name}\\n\"\\\n",
    "    #        \"    return result\" \n",
    "\n",
    "    #result = bos.format(name=name, query=query) + code + eos.format(name=name)\n",
    "\n",
    "    file = open('/home/langchain-tools/examples/new_tool.py', mode='w')\n",
    "    file.write(code)\n",
    "    file.close()\n",
    "\n",
    "    return 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolmaking agent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finish'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = 'Output multiples of 3 up to 20'\n",
    "toolmaking_agent(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実行するLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executing_agent(input_, tools_):\n",
    "    print(\"executing agent\")\n",
    "\n",
    "    excute_llm = OpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "    agent = initialize_agent(tools_, excute_llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "    agent.run(input_)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input_, exec_list_, tools_):\n",
    "    \n",
    "    output = deciding_agent(input_, exec_list_)\n",
    "\n",
    "    if output == \"Yes\":\n",
    "        print('Execute it as it is executable without creating a tool.')\n",
    "        executing_agent(input_, tools_)\n",
    "\n",
    "    elif output == \"No\":\n",
    "        print('It is necessary to create a tool, so run it after creating the tool.')\n",
    "        toolmaking_agent(input_)\n",
    "\n",
    "        tools.append(Tool(name = f'{new_tool}', func = new_tool.new_tool, description=''))\n",
    "\n",
    "        executing_agent(input_, tools_)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0efafe6c13c226858b1e3209a708328284172effb51c12dbb0bda90f2bc21738"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
