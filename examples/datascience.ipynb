{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fuyu-quant/langchain-tools/blob/main/examples/datascience.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fuyu-quant/langchain-tools.git\n",
      "  Cloning https://github.com/fuyu-quant/langchain-tools.git to /tmp/pip-req-build-245z6wvj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/fuyu-quant/langchain-tools.git /tmp/pip-req-build-245z6wvj\n",
      "  Resolved https://github.com/fuyu-quant/langchain-tools.git to commit 90f8145b475870c9c78f774bdf04a64736ff823b\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: langchaintools\n",
      "  Building wheel for langchaintools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langchaintools: filename=langchaintools-0.2.0-py3-none-any.whl size=9421 sha256=28b9248eb78f4cdb25504f2d4a766e05499c02c9565be0d8baf1bc2ac00e7404\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-g7dynff2/wheels/ea/fc/e9/fd85c3556513c353cf0eaee43cd7473ffc93461ab46e639ae5\n",
      "Successfully built langchaintools\n",
      "Installing collected packages: langchaintools\n",
      "  Attempting uninstall: langchaintools\n",
      "    Found existing installation: langchaintools 0.1.1\n",
      "    Uninstalling langchaintools-0.1.1:\n",
      "      Successfully uninstalled langchaintools-0.1.1\n",
      "Successfully installed langchaintools-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fuyu-quant/langchain-tools.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain==0.0.152\n",
    "!pip install openai==00.27.5\n",
    "!pip install lightgbm==3.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "\n",
    "\n",
    "# langchaintools \n",
    "from langchaintools import mltools\n",
    "from langchaintools import preprocessingtools as ppt\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [mltools.LgbmTrainTool(), \n",
    "        mltools.LgbmInferenceTool(),\n",
    "        ppt.OnehotEncodingTool(), \n",
    "        ppt.LabelEncodingTool(),\n",
    "        ppt.TargetEncodingTool(),\n",
    "        ppt.File0Tool(),\n",
    "        ppt.FileMeansTool(),\n",
    "        ppt.FileMedianTool(),\n",
    "        ppt.MakeDatasetTool()\n",
    "        ]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m LightGBMを使って推論する必要がある\n",
      "Action: lgbm_inference_tool\n",
      "Action Input: target\u001b[0m"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'trained_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLightGBMで推論してください。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;132;01m{input_}\u001b[39;00m\u001b[38;5;124m一度toolを使ったら必ず終了してください．\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m目的変数は\u001b[39m\u001b[38;5;132;01m{target_}\u001b[39;00m\u001b[38;5;124mです．\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(input_\u001b[38;5;241m=\u001b[39m\u001b[38;5;28minput\u001b[39m, target_\u001b[38;5;241m=\u001b[39mtarget)\n\u001b[0;32m---> 19\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:213\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    212\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 213\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m])[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:116\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[0;32m--> 116\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_end(outputs, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(inputs, outputs, return_only_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py:113\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[1;32m    108\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m},\n\u001b[1;32m    109\u001b[0m     inputs,\n\u001b[1;32m    110\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose,\n\u001b[1;32m    111\u001b[0m )\n\u001b[1;32m    112\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs)\n\u001b[1;32m    114\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_chain_error(e, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:796\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m--> 796\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[1;32m    797\u001b[0m         name_to_tool_map, color_mapping, inputs, intermediate_steps\n\u001b[1;32m    798\u001b[0m     )\n\u001b[1;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m    800\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(next_step_output, intermediate_steps)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/agents/agent.py:699\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps)\u001b[0m\n\u001b[1;32m    697\u001b[0m         tool_run_kwargs[\u001b[39m\"\u001b[39m\u001b[39mllm_prefix\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    698\u001b[0m     \u001b[39m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     observation \u001b[39m=\u001b[39m tool\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    700\u001b[0m         agent_action\u001b[39m.\u001b[39;49mtool_input,\n\u001b[1;32m    701\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    702\u001b[0m         color\u001b[39m=\u001b[39;49mcolor,\n\u001b[1;32m    703\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_run_kwargs,\n\u001b[1;32m    704\u001b[0m     )\n\u001b[1;32m    705\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     tool_run_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/tools/base.py:189\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_error(e, verbose\u001b[39m=\u001b[39mverbose_)\n\u001b[0;32m--> 189\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_end(\n\u001b[1;32m    191\u001b[0m     \u001b[39mstr\u001b[39m(observation), verbose\u001b[39m=\u001b[39mverbose_, color\u001b[39m=\u001b[39mcolor, name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchain/tools/base.py:186\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     tool_args, tool_kwargs \u001b[39m=\u001b[39m _to_args_and_kwargs(tool_input)\n\u001b[0;32m--> 186\u001b[0m     observation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(\u001b[39m*\u001b[39;49mtool_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mtool_kwargs)\n\u001b[1;32m    187\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    188\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_manager\u001b[39m.\u001b[39mon_tool_error(e, verbose\u001b[39m=\u001b[39mverbose_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/langchaintools/mltools/lightgbm.py:82\u001b[0m, in \u001b[0;36mLgbmInferenceTool._run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     78\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/home/langchain-tools/data/test.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrained_model.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 82\u001b[0m lgbm_model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39;49m(file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     84\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/home/langchain-tools/data/test.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     85\u001b[0m X \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop([query], axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'trained_model.pkl'"
     ]
    }
   ],
   "source": [
    "target = 'target'\n",
    "\n",
    "#input = \"カラム名がSexのone-hotエンコーディングを行ってください。\"\n",
    "#input = \"カラム名がEmbarkedのラベルエンコーディングを行ってください。\"\n",
    "#input = \"カラム名がSex_femaleのターゲットエンコーディングを行ってください。\"\n",
    "#input = \"カラム名がAgeの欠損値を0で埋めてください。\"\n",
    "#input = \"train.csvとeval.csvを作成してください。\"\n",
    "\n",
    "#input = \"LightGBMで学習してください。推論はしないでください\"\n",
    "input = \"LightGBMで推論してください。\"\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "{input_}一度toolを使ったら必ず終了してください．\n",
    "目的変数は{target_}です．\n",
    "\"\"\".format(input_=input, target_=target)\n",
    "\n",
    "\n",
    "agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to find the name of the feature in the dataframe\n",
      "Action: python_repl_ast\n",
      "Action Input: df.columns\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndex(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the names of the features\n",
      "Final Answer: df.columns\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "特徴量の名前を教えてください\n",
      "\n",
      "\n",
      "Please tell me the name of the feature.The operation must be applied directly to the original dataframe.The answer must be just python code\n",
      "df.columns\n"
     ]
    }
   ],
   "source": [
    "query = \"特徴量の名前を教えてください\"\n",
    "output = chat_tool_with_pandas_df(df_, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = pd.read_csv('/home/langchain-tools/data/train.csv')\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin Embarked  Sex_female  Sex_male  \n",
       "0         A/5 21171   7.2500   NaN        S           0         1  \n",
       "1          PC 17599  71.2833   C85        C           1         0  \n",
       "2  STON/O2. 3101282   7.9250   NaN        S           1         0  \n",
       "3            113803  53.1000  C123        S           1         0  \n",
       "4            373450   8.0500   NaN        S           0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df_, columns=['Sex'])\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnehotEncodingTool(BaseTool):\n",
    "    name = \"onehot_encoding_tool\"\n",
    "    description = \"\"\"It is useful for onehot encoding when column names are given. The input should be a column name.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "        df = pd.get_dummies(df, columns=[query])\n",
    "        df.to_csv('/home/langchain-tools/data/train2.csv', index=False)\n",
    "\n",
    "        result = \"one-hot encoding has been completed. \" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class LabelEncodingTool(BaseTool):\n",
    "    name = \"label_encoding_tool\"\n",
    "    description = \"\"\"It is useful for label encoding when column names are given. The input should be a column name.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "        le = LabelEncoder()\n",
    "        df[query] = le.fit_transform(df[query])\n",
    "        df.to_csv('/home/langchain-tools/data/train2.csv', index=False)\n",
    "\n",
    "        result = \"label encoding has been completed. \" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder\n",
    "\n",
    "class TargetEncodingTool(BaseTool):\n",
    "    name = \"target_encoding_tool\"\n",
    "    description = \"\"\"It is useful for target encoding when column names are given. The input receives the column names of the target column and the column name of the objective variable, separated by commas, such as 'A,B'.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        a, b = query.split(\",\")\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "        te = TargetEncoder()\n",
    "        df[a] = df[a].astype(str)\n",
    "        df[a] = te.fit_transform(df[a], df[b])\n",
    "        df.to_csv('/home/langchain-tools/data/train2.csv', index=False)\n",
    "\n",
    "        result = \"target encoding has been completed. \" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class File0Tool(BaseTool):\n",
    "    name = \"file_0_tool\"\n",
    "    description = \"\"\"It is useful to fill in missing values with zeros when a column name is received. The input should be a column name.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "        df[query] = df[query].fillna(0)\n",
    "        df.to_csv('/home/langchain-tools/data/train2.csv', index=False)\n",
    "\n",
    "        result = \"The missing values could be filled with 0.\" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileMeansTool(BaseTool):\n",
    "    name = \"file_means_tool\"\n",
    "    description = \"\"\"It is useful to fill in missing values with means when a column name is received. The input should be a column name.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "        df[query] = df[query].fillna(df[query].mean())\n",
    "        df.to_csv('/home/langchain-tools/data/train2.csv', index=False)\n",
    "\n",
    "        result = \"The missing values could be filled with means.\" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileMedianTool(BaseTool):\n",
    "    name = \"file_median_tool\"\n",
    "    description = \"\"\"It is useful to fill in missing values with median when a column name is received. The input should be a column name.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/sample2.csv')\n",
    "        df[query] = df[query].fillna(df[query].median())\n",
    "        df.to_csv('/home/langchain-tools/data/sample2.csv', index=False)\n",
    "\n",
    "        result = \"The missing values could be filled with median.\" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class MakeDatasetTool(BaseTool):\n",
    "    name = \"make_dataset_tool\"\n",
    "    description = \"\"\"It is useful to create train.csv and eval.csv. The column name of the target variable is used as input.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/sample2.csv')\n",
    "        X = df.drop(query, axis=1)\n",
    "        y = df[query]\n",
    "\n",
    "        # 学習データと評価データに分割\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X, y, test_size=0.25, random_state=3655)\n",
    "\n",
    "        X_train[query] = y_train\n",
    "        X_eval[query] = y_eval\n",
    "        \n",
    "        X_train.to_csv('/home/langchain-tools/data/train.csv', index=False)\n",
    "        X_eval.to_csv('/home/langchain-tools/data/eval.csv', index=False)\n",
    "\n",
    "        result = \"train.csv and eval.csv have been created.\" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [OnehotEncodingTool(), LabelEncodingTool(),TargetEncodingTool(),\n",
    "            File0Tool(),FileMeansTool(),FileMedianTool(),MakeDatasetTool()]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to create train.csv and eval.csv with the target variable being Survived.\n",
      "Action: make_dataset_tool\n",
      "Action Input: Survived\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mtrain.csv and eval.csv have been created.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: train.csv and eval.csv have been created with the target variable being Survived.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'train.csv and eval.csv have been created with the target variable being Survived.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input = \"カラム名がSexのone-hotエンコーディングを行ってください。\"\n",
    "#input = \"カラム名がEmbarkedのラベルエンコーディングを行ってください。\"\n",
    "#input = \"カラム名がSex_femaleのターゲットエンコーディングを行ってください。目的変数はSurvivedです\"\n",
    "#input = \"カラム名がAgeの欠損値を0で埋めてください。\"\n",
    "input = \"train.csvとeval.csvを作成してください。目的変数はSurvivedです。\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "{input_}一度toolを使ったら終了してください．\n",
    "\"\"\".format(input_=input)\n",
    "\n",
    "\n",
    "agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  Sex_female  Sex_male  \n",
       "0         A/5 21171   7.2500   NaN         2    0.188908         1  \n",
       "1          PC 17599  71.2833   C85         0    0.742038         0  \n",
       "2  STON/O2. 3101282   7.9250   NaN         2    0.742038         0  \n",
       "3            113803  53.1000  C123         2    0.742038         0  \n",
       "4            373450   8.0500   NaN         2    0.188908         1  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/langchain-tools/data/train2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  PassengerId  Survived  Pclass  \\\n",
       "0             0           0            1         0       3   \n",
       "1             1           1            2         1       1   \n",
       "2             2           2            3         1       3   \n",
       "3             3           3            4         1       1   \n",
       "4             4           4            5         0       3   \n",
       "\n",
       "                                                Name   Age  SibSp  Parch  \\\n",
       "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
       "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
       "4                           Allen, Mr. William Henry  35.0      0      0   \n",
       "\n",
       "             Ticket     Fare Cabin  Embarked  Sex_female  Sex_male  \n",
       "0         A/5 21171   7.2500   NaN         2           0         1  \n",
       "1          PC 17599  71.2833   C85         0           1         1  \n",
       "2  STON/O2. 3101282   7.9250   NaN         2           1         0  \n",
       "3            113803  53.1000  C123         2           1         1  \n",
       "4            373450   8.0500   NaN         2           0         0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TargetEncoder()\n",
    "df['Sex_male'] = te.fit_transform(df['SibSp'], df['Survived'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, r2_score\n",
    "\n",
    "from langchain.tools import BaseTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LgbmTrainTool(BaseTool):\n",
    "    name = \"lgbm_train_tool\"\n",
    "    description = \"\"\"It is useful for learning LightGBM. The input is the column name of the target variable.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "      \"\"\"Use the tool.\"\"\"\n",
    "      \n",
    "      df = pd.read_csv('/home/langchain-tools/data/train.csv')\n",
    "      x = df.drop([query], axis = 1)\n",
    "      y = df[query]\n",
    "\n",
    "      x_train,x_valid,y_train,y_valid = train_test_split(x, y ,test_size = 0.2, random_state=3655)\n",
    "\n",
    "      # categorical features\n",
    "      categorical_features = []\n",
    "      for i in df.columns:\n",
    "          if df[i].dtypes == 'category':\n",
    "              categorical_features.append(i)\n",
    "\n",
    "\n",
    "      lgb_train = lgbm.Dataset(x_train,y_train,categorical_feature=categorical_features,free_raw_data=False)\n",
    "      lgb_eval = lgbm.Dataset(x_valid,y_valid,reference=lgb_train,categorical_feature=categorical_features,free_raw_data=False)\n",
    "\n",
    "\n",
    "      # number of classes of the objective variable\n",
    "      num_class = len(df[query].unique())\n",
    "      if num_class == 2:\n",
    "          params = {'task': 'train', 'boosting_type': 'gbdt','objective': 'binary', 'metric': 'auc', 'verbose': -1}\n",
    "      elif num_class <= 50:\n",
    "          params = {'task': 'train', 'boosting_type': 'gbdt','objective': 'multiclass', 'metric': 'multi_logloss','num_class': num_class, 'verbose': -1}\n",
    "      else:\n",
    "          params = {'task': 'train', 'boosting_type': 'gbdt','objective': 'regression','metric': 'rmse', 'verbose': -1}\n",
    "\n",
    "\n",
    "      lgbm_model = lgbm.train(\n",
    "          params,\n",
    "          lgb_train,\n",
    "          valid_sets=[lgb_train,lgb_eval],\n",
    "          verbose_eval=10,\n",
    "          #num_boost_round=1000,\n",
    "          )\n",
    "      \n",
    "\n",
    "      file = '/home/langchain-tools/data/trained_model.pkl'\n",
    "      pickle.dump(lgbm_model, open(file, 'wb'))\n",
    "\n",
    "      split_df = pd.DataFrame(lgbm_model.feature_importance(importance_type = 'split'),index = x.columns, columns=['split_importance']).sort_values('split_importance', ascending=False)\n",
    "      gain_df = pd.DataFrame(lgbm_model.feature_importance(importance_type = 'gain'),index = x.columns,columns=['gain_importance'])\n",
    "      importance = split_df.join(gain_df)\n",
    "      importance.to_csv('/home/langchain-tools/data/importance.csv')\n",
    "\n",
    "      result = \"LightGBM learning is complete.\"\n",
    "      return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")\n",
    "\n",
    "\n",
    "class LgbmInferenceTool(BaseTool):\n",
    "    name = \"lgbm_inference_tool\"\n",
    "    description = \"\"\"It is useful for inference using LightGBM. The input is the column name of the objective variable.\"\"\"\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        df = pd.read_csv('/home/langchain-tools/data/test.csv')\n",
    "\n",
    "\n",
    "        file = 'trained_model.pkl'\n",
    "        lgbm_model = pickle.load(open(file, 'rb'))\n",
    "\n",
    "        df = pd.read_csv('/home/langchain-tools/data/test.csv')\n",
    "        X = df.drop([query], axis = 1)\n",
    "        y = df[query]\n",
    "\n",
    "        num_class = len(df[query].unique())\n",
    "        # binary classification\n",
    "        if num_class == 2:\n",
    "            y_pred = lgbm_model.predict(X, num_interation=lgbm_model.best_iteration)\n",
    "            roc_auc = roc_auc_score(y, y_pred)\n",
    "            y_pred_binary = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "            accuracy = accuracy_score(y, y_pred_binary)\n",
    "            df_report = pd.DataFrame([roc_auc, accuracy], index=['roc_auc', 'accuracy'], columns=['score'])\n",
    "            df_report.to_csv('/home/langchain-tools/data/report.csv')\n",
    "\n",
    "        \n",
    "        # multiclass classification\n",
    "        elif num_class <= 50:\n",
    "            y_pred = lgbm_model.predict(X, num_interation=lgbm_model.best_iteration)\n",
    "            y_pred_class = [np.argmax(pred) for pred in y_pred]\n",
    "            accuracy = accuracy_score(y, y_pred_class)\n",
    "            #conf_mat = confusion_matrix(y, y_pred_class)\n",
    "            df_report = pd.DataFrame([accuracy], index=['accuracy'], columns=['score'])\n",
    "            df_report.to_csv('/home/langchain-tools/data/report.csv')\n",
    "\n",
    "\n",
    "        \n",
    "        # regression\n",
    "        else:\n",
    "            y_pred = lgbm_model.predict(X, num_interation=lgbm_model.best_iteration)\n",
    "            mse = mean_squared_error(y, y_pred)\n",
    "            r2 = r2_score(y, y_pred)\n",
    "            df_report = pd.DataFrame([mse, r2], index=['mse', 'r2'], columns=['score'])\n",
    "            df_report.to_csv('/home/langchain-tools/data/report.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        result = \"LightGBM inference is complete.\" \n",
    "        return result\n",
    "\n",
    "    async def _arun(self, query: str) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"BingSearchRun does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OnehotEncodingTool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tools \u001b[38;5;241m=\u001b[39m [LgbmTrainTool(), LgbmInferenceTool(),\u001b[43mOnehotEncodingTool\u001b[49m(), LabelEncodingTool(),TargetEncodingTool(),\n\u001b[1;32m      2\u001b[0m             File0Tool(),FileMeansTool(),FileMedianTool(),MakeDatasetTool()]\n\u001b[1;32m      4\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m agent \u001b[38;5;241m=\u001b[39m initialize_agent(tools, llm, agent\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero-shot-react-description\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OnehotEncodingTool' is not defined"
     ]
    }
   ],
   "source": [
    "tools = [LgbmTrainTool(), LgbmInferenceTool(),OnehotEncodingTool(), LabelEncodingTool(),TargetEncodingTool(),\n",
    "            File0Tool(),FileMeansTool(),FileMedianTool(),MakeDatasetTool()]\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m LightGBMを使って推論する必要がある\n",
      "Action: lgbm_inference_tool\n",
      "Action Input: target\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mLightGBM inference is complete.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 目的変数を推論したので終了\n",
      "Final Answer: LightGBM inference is complete.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LightGBM inference is complete.'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input = \"LightGBMで学習してください。推論はしないでください\"\n",
    "input = \"LightGBMで推論してください。\"\n",
    "\n",
    "target = 'target'\n",
    "\n",
    "prompt = \"\"\"\n",
    "{input_}一度toolを使ったら必ず終了してください．\n",
    "目的変数は{target_}です．\n",
    "\"\"\".format(input_=input, target_=target)\n",
    "\n",
    "\n",
    "agent.run(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
