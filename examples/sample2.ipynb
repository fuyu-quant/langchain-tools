{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain==0.0.167\n",
    "!pip install openai==0.27.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent, Tool, tool\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class LCTAGI():\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name = 'gpt-4'\n",
    "        ):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    \n",
    "    def _generalize(self, input_prompt_):\n",
    "        print(\"> Generalize the input task.\")\n",
    "\n",
    "        generalize_llm = OpenAI(temperature=0,model_name = self.model_name)\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        Please generalize the following sentences by replacing any numerical or other parts of the sentences with letters.\n",
    "        Output is only the text after rewriting.\n",
    "\n",
    "        ------------\n",
    "        {input}\n",
    "        ------------\n",
    "        \"\"\".format(input = input_prompt_)\n",
    "\n",
    "        responese = generalize_llm(prompt)\n",
    "\n",
    "        print('\\033[32m' + f'Generalized Task：{responese}\\n' + '\\033[0m')\n",
    "\n",
    "        return responese\n",
    "        \n",
    "\n",
    "    def _decide(self, input_prompt_, tools_):\n",
    "        print(\"> Determine if you should make a tool.\")\n",
    "        \n",
    "        decide_llm = OpenAI(temperature=0,model_name = self.model_name)\n",
    "\n",
    "        description_list = ''\n",
    "        for tool_ in tools_:\n",
    "            description = tool_.description\n",
    "            description_list += description + ','\n",
    "        description_list = '[' + description_list + ']'\n",
    "\n",
    "        prompt = \"\"\"\n",
    "        You are an agent that determines if the input task is executable. \n",
    "        All you can do is to be included in {exec_list}. \n",
    "        Answer \"Yes.\" if you can perform the task, or \"No.\" if you cannot.\n",
    "        \n",
    "        -----------\n",
    "        The entered task is:{input}\n",
    "        -----------\n",
    "        \"\"\".format(exec_list = description_list, input = input_prompt_)\n",
    "\n",
    "        responese = decide_llm(prompt)\n",
    "\n",
    "        if responese == \"Yes.\":\n",
    "            print('\\033[32m' + 'I do not need to create a tool to run it.\\n' + '\\033[0m')\n",
    "\n",
    "        elif responese == \"No.\":\n",
    "            print('\\033[32m' + 'I must create the tool before executing.\\n' + '\\033[0m')\n",
    "\n",
    "\n",
    "        return responese\n",
    "\n",
    "\n",
    "    def _tool_make(self, input_prompt_, folder_path_):\n",
    "        print(\"> Create a tool.\")\n",
    "\n",
    "        tool_llm = OpenAI(temperature=0, model_name = self.model_name)\n",
    "\n",
    "\n",
    "        create_prompt = \"\"\"\n",
    "        Create a python class that can execute {input} with a single string as input.\n",
    "        Output should be code only.\n",
    "        The following code was created with the input \"multiply two numbers\". Please create it like this code.\n",
    "        Do not enclose the output in ``python ``` or the like.\n",
    "        Class must inherit from BaseTool.\n",
    "        \n",
    "        ------------------\n",
    "        class MultiplicationTool(BaseTool):\n",
    "            name = \"MultiplicationTool\"\n",
    "            description = \"used for multiplication. The input is two numbers. For example, if you want to multiply 1 by 2, the input is '1,2'.\"\n",
    "\n",
    "            def _run(self, query: str) -> str:\n",
    "                \"Use the tool.\"\n",
    "                a, b = query.split(\",\")\n",
    "                c = int(a) * int(b)\n",
    "                result = c\n",
    "\n",
    "            return result \n",
    "\n",
    "            async def _arun(self, query: str) -> str:\n",
    "                \"Use the tool asynchronously.\"\n",
    "                raise NotImplementedError(\"MultiplicationTool does not support async\")\n",
    "        ------------------\n",
    "        \"\"\".format(input = input_prompt_)\n",
    "\n",
    "        code = tool_llm(create_prompt)\n",
    "\n",
    "\n",
    "\n",
    "        name_prompt = \"\"\"\n",
    "        Extract the class name from the following code.\n",
    "        The final output is only the extracted content.\n",
    "\n",
    "        ------------------\n",
    "        {code}\n",
    "        ------------------\n",
    "        \"\"\".format(code = code)\n",
    "\n",
    "        name = tool_llm(name_prompt)\n",
    "        print('\\033[32m' + 'Completed!')\n",
    "        print('Created tool name：' + name + '\\n' + '\\033[0m')\n",
    "\n",
    "        # Save to File\n",
    "        if folder_path_ != None:\n",
    "            with open(folder_path_ + f'{name}.py', mode='w') as file:\n",
    "                file.write(code)\n",
    "        \n",
    "\n",
    "        return name, code\n",
    "\n",
    "\n",
    "    def _execute(self,input_prompt_, tools_):\n",
    "        excute_llm = OpenAI(temperature=0, model_name = self.model_name)\n",
    "\n",
    "        agent = initialize_agent(tools_, excute_llm, agent=\"zero-shot-react-description\", verbose=True)\n",
    "\n",
    "        agent.run(input_prompt_)\n",
    "\n",
    "        return\n",
    "\n",
    "\n",
    "    def run(self, input_prompt_, tools_, folder_path_ = None):\n",
    "\n",
    "        generalized_task = self._generalize(input_prompt_)\n",
    "    \n",
    "        output = self._decide(generalized_task, tools_)\n",
    "\n",
    "        if output == \"Yes.\":\n",
    "            self._execute(input_prompt_, tools_)\n",
    "\n",
    "        elif output == \"No.\":\n",
    "            new_tool_name, new_tool_code = self._tool_make(generalized_task, folder_path_)\n",
    "\n",
    "            new_tool_code = new_tool_code + '\\n' + f'new_tool = {new_tool_name}()'\n",
    "\n",
    "            exec(new_tool_code, globals())\n",
    "          \n",
    "            tools_.append(new_tool)\n",
    "            \n",
    "            self._execute(input_prompt_, tools_)\n",
    "        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Generalize the input task.\n",
      "\u001b[32mGeneralized Task：Sum of prime numbers from A to B\n",
      "\u001b[0m\n",
      "> Determine if you should make a tool.\n",
      "\u001b[32mI must create the tool before executing.\n",
      "\u001b[0m\n",
      "> Create a tool.\n",
      "\u001b[32mCompleted!\n",
      "Created tool name：SumOfPrimesTool\n",
      "\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find the sum of prime numbers between 1 and 50. I can use the SumOfPrimesTool for this task.\n",
      "Action: SumOfPrimesTool\n",
      "Action Input: 1,50\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m328\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "input = 'Sum of prime numbers from 1 to 50'\n",
    "\n",
    "folder_path = '/home/langchain-tools/data/'\n",
    "tools = []\n",
    "\n",
    "lctagi = LCTAGI()\n",
    "\n",
    "lctagi.run(input, tools, folder_path)\n",
    "\n",
    "#lctagi.run(input, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
